{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Merel van den Bos\n",
    "- Alex Rivera\n",
    "- Lillian Wood\n",
    "- Albert Aung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "Every day, individuals leave reviews on the popular online gaming storefront Steam. People often go into great detail reviewing their favorite or least favorite games, making this a ripe field for sentiment analysis. Our goal is to train a model to detect the sentiment of a Steam user's review and be able to relay if this person enjoyed the game or not, and to what extent. We will be training a model with a large labelled dataset of reviews. Success will be measured by how accurately the model is able to detect whether a review is positive or negative, and if the person recommended the game or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Steam is a highly-used online marketplace for P.C. videogames. The popularity of the platform has developed into a social feature by housing the P.C. gaming community and connecting friends through muutually-played games. An important feature of Steam, both as a marketplace and a social sphere, is the ability to write, read, and rate reviews for games. \n",
    "\n",
    "The plethora of review on Steam provides both an interesting and abundant source of text with potential to drive useful sentiment analysis models. In their paper, \"Steam Review Dataset - new, large scale sentiment dataset,\" Sobkowicz and Stokowiec introduce a dataset which they claim could be a powerful source of consumer data for sentiment analysis <a name=\"Sobkowicz\"></a>[<sup>[1]</sup>](#Sobkowicz). Utlizing these reviews has relevant and important implications. Since these reviews act as consumer data, conclusions drawn from these reviews inform both gamers and game developers about successful and worthwile games. Additionally, the function of reviewing is a very powerful feature, providing gamers with a voice that directly impacts which games sell and which games flop <a name=\"Sobkowicz\"></a>[<sup>[1]</sup>](#Sobkowicz). It would be highly valuable for both development of future games and for satisfaction of gamers to tailor the review system to be effective and informative.\n",
    "\n",
    "As it stands, reviews consist of both written commentary and a \"Yes\" (thumbs-up) or \"No\" (thumbs-down). The Yes and No ratings for each game are averaged to create two summative ratings which appear underneath the synopsis of the game when a user views the game's page. \"Recent Reviews\" averages the number of positive and negative recent reviews. \"All\" averages the number of all positive and negative reviews. The summative ratings are labeled on a scale of: overwhelmingly negative, very negative, negative, mostly negative, mixed, mostly positive, positive, very positive, overwhelmingly positive. \n",
    "\n",
    "Although this feedback is already incredibly helpful to gamers and game developers, it is questionable whether the data is entirely accurate. As they stand, the summative ratings are binary, only based on \"Yes\" or \"No.\" There is no way to account for partially liking or disliking a game. Forcing users to choose between Yes or No may skew the ratings incorrectly, since there is no middle ground. Therefore, it would be useful to also summatively analyze the written data in order to develop a a more well-rounded summary of a game's reviews. \n",
    "\n",
    "We propose the most meaningful way to analyze and summarize a game's written reviews would be to perform a sentiment analysis to predict the rating of a game based on the written reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once).\n",
    " - `We are going to predict the rating of a game based on Steam reviews by utilizing sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "You should have a strong idea of what dataset(s) will be used to accomplish this project. \n",
    "\n",
    "If you know what (some) of the data you will use are please give the following infomration for each dataset\n",
    "- https://www.kaggle.com/datasets/andrewmvd/steam-reviews\n",
    "- description of the size of the dataset (# of variables, # of observations): 'The dataset contains over 6.4 million publicly available reviews in English from Steam Reviews portion of Steam store run by Valve. Each review is described by review text, the id of game it belongs to, review sentiment (positive or negative) and a number of users who thought the review was helpful.'\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc will be needed\n",
    "\n",
    "If you don't yet know what your dataset(s) will be, you should be able to describe what you desire in terms of the above bullets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic (Pel√©) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"Sobkowicz\"></a>1.[^](#Sobkowicz): Sobkowicz, Antoni & Stokowiec, Wojciech. (2016). Steam Review Dataset - new, large scale sentiment dataset. <br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
